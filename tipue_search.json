{
    "pages": [
        {
            "title": "MongoDB CLI Intro", 
            "text":"MongoDB CLI Intro After publishing my article on How to install MongoDB on Linux I realized that I should have covered how to access it through the command line! Didn&#39;t occur to me that anyone reading it might not want to download and install Robo 3T! Sorry about that! Intro into the mongo cli app It&#39;s simple enough. Now I&#39;m no expert but this is what I discovered just playing around with it. (base) ➜ ~ mongo MongoDB shell version v4.2.3 connecting to: mongodb://127.0.0.1:27017/?compressors=disabled&amp;gssapiServiceName=mongodb Implicit session: session { &#34;id&#34; : UUID(&#34;39eaf67e-7de5-4874-ba3e-a6673080cfbc&#34;) } MongoDB server version: 4.2.3 Welcome to the MongoDB shell. For interactive help, type &#34;help&#34;. For more comprehensive documentation, see http://docs.mongodb.org/ Questions? Try the support group http://groups.google.com/group/mongodb-user Server has startup warnings: 2020-03-06T20:35:19.314-0600 I STORAGE [initandlisten] 2020-03-06T20:35:19.314-0600 I STORAGE [initandlisten] ** WARNING: Using the XFS filesystem is strongly recommended with the WiredTiger storage engine 2020-03-06T20:35:19.314-0600 I STORAGE [initandlisten] ** See http://dochub.mongodb.org/core/prodnotes-filesystem 2020-03-06T20:35:22.538-0600 I CONTROL [initandlisten] 2020-03-06T20:35:22.539-0600 I CONTROL [initandlisten] ** WARNING: Access control is not enabled for the database. 2020-03-06T20:35:22.539-0600 I CONTROL [initandlisten] ** Read and write access to data and configuration is unrestricted. 2020-03-06T20:35:22.539-0600 I CONTROL [initandlisten] --- Enable MongoDB&#39;s free cloud-based monitoring service, which will then receive and display metrics about your deployment (disk utilization, CPU, operation statistics, etc). The monitoring data will be available on a MongoDB website with a unique URL accessible to you and anyone you share the URL with. MongoDB may use this information to make product improvements and to suggest MongoDB products and deployment options to you. To enable free monitoring, run the following command: db.enableFreeMonitoring() To permanently disable this reminder, run the following command: db.disableFreeMonitoring() --- &gt; As you can tell, I haven&#39;t secured the database yet. Let&#39;s continue exploring though and see what the help command will show us. &gt; help db.help() help on db methods db.mycoll.help() help on collection methods sh.help() sharding helpers rs.help() replica set helpers help admin administrative help help connect connecting to a db help help keys key shortcuts help misc misc things to know help mr mapreduce show dbs show database names show collections show collections in current database show users show users in current database show profile show most recent system.profile entries with time &gt;= 1ms show logs show the accessible logger names show log [name] prints out the last segment of log in memory, &#39;global&#39; is default use &lt;db_name&gt; set current database db.foo.find() list objects in collection foo db.foo.find( { a : 1 } ) list objects in foo where a == 1 it result of the last line evaluated; use to further iterate DBQuery.shellBatchSize = x set default number of items to display on shell exit &gt; Ok, looks simple enough. That show dbs sounds interesting. &gt; show dbs admin 0.000GB config 0.000GB local 0.000GB snake_bnb 0.000GB &gt; Ok, I see the snake_bnb database that we created during the MongoDB Quickstart tutorial. Let&#39;s see what&#39;s in it with that use &lt;db_name&gt; command, followed by show collections. &gt; use snake_bnb switched to db snake_bnb &gt; show collections owners &gt; Now if I reference the help command again, I see that I can use db.foo.find() to do a dump of everything in it. &gt; db.owners.find() { &#34;_id&#34; : ObjectId(&#34;5e6243ca45ed06e7f09781fc&#34;), &#34;registered_date&#34; : ISODate(&#34;2020-03-06T06:36:26.108Z&#34;), &#34;name&#34; : &#34;clamytoe&#34;, &#34;email&#34; : &#34;clamytoe@gmail.com&#34;, &#34;snake_ids&#34; : [ ], &#34;cage_ids&#34; : [ ] } &gt; If I had more entries, it looks like I could search for specific entries with db.foo.find( { a : 1 } ). I only have one record, so I should just get the same result as the previous command. &gt; db.owners.find( {&#34;name&#34;: &#34;clamytoe&#34;} ) { &#34;_id&#34; : ObjectId(&#34;5e6243ca45ed06e7f09781fc&#34;), &#34;registered_date&#34; : ISODate(&#34;2020-03-06T06:36:26.108Z&#34;), &#34;name&#34; : &#34;clamytoe&#34;, &#34;email&#34; : &#34;clamytoe@gmail.com&#34;, &#34;snake_ids&#34; : [ ], &#34;cage_ids&#34; : [ ] } &gt; To exit, we just use the exit command. &gt; exit bye (base) ➜ ~ Conclusion There you have it. A quick intro into using the mongo cli app. Simple enough for quick exploration of your databases. I&#39;ll probably be spending more time in Robo 3T though. Not only can your explore the databases through a GUI, but you can also easily add, delete, and update and entries with it.", 
            "tags": "Database", 
            "loc": "https://clamytoe.github.io/articles/2020/Mar/07/mongodb-cli-intro"
        },
        {
            "title": "How to install MongoDB on Linux", 
            "text":"How to install MongoDB on Linux So the other day I started going through Michael Kennedy&#39;s free MongoDB Quickstart course. Although he covered the Python code portions, he left getting everything setup, up to you. If you&#39;re on a Linux machine that uses APT, then keep on reading. Getting MongoDB I could have gone over to MongoDB&#39;s download page, and selected the correct version for my setup, but I wanted to stick with the package manager on my machine. The latest version as of this writing was 4.2. The first thing I had to do was find their public key and import it to APT. Importing MongoDB&#39;s security key To make sure that I had the required gnupg package installed, I ran the following command: sudo apt-get install gnupg. Once that was taken care off, I imported the key: wget -qO - https://www.mongodb.org/static/pgp/server-4.2.asc | sudo apt-key add - Creating a new source for APT The next thing I did was to find the codename for my system&#39;s release. I did that with the following command: grep -i /etc/os-release VERSION_CODENAME=tricia UBUNTU_CODENAME=bionic There it was. My Linux Mint system is based on bionic. Now to create an entry for MongoDB in APT&#39;s source list directory /etc/apt/sources.list.d/, I created mongodb-org.4.2.list with the following content: deb [arch=amd64] https://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.2 multiverse I had to look at other entries in there until I got the format correct. Don&#39;t worry, if you get it wrong, it will let you know when you try to do an update! Update APT At this point it was time to update APT and install mongoDB: sudo apt-get update sudo apt-get install -y mongodb-org Starting MongoDB Once everything was installed, it was time to fire up the service so that I could connect to it. sudo systemctl start mongod Now, that command will start the server for this session only. Which means that the next time that I reboot, I will have to start it again. I wanted the service to always be available, so I did the following: sudo systemctl enable mongod.service sudo systemctl daemon-reload sudo systemctl restart mongod.service To verify that it was running, I used this command: systemctl status mongod ● mongod.service - MongoDB Database Server Loaded: loaded (/lib/systemd/system/mongod.service; enabled; vendor preset: e Active: active (running) since Fri 2020-03-06 20:35:16 CST; 12s ago Docs: https://docs.mongodb.org/manual Main PID: 8569 (mongod) CGroup: /system.slice/mongod.service └─8569 /usr/bin/mongod --config /etc/mongod.conf Mar 06 20:35:16 SERENiTY systemd[1]: Started MongoDB Database Server. If you want the server to restart after a crash, you would need to add Restart=always under the [Service] section of /lib/systemd/system/mongod.service. I didn&#39;t add that. At this point, a reboot would be useful to make sure that it starts up at boot. If you decide that you don&#39;t want it running all of the time, just disable it. sudo systemctl stop mongod sudo systemctl disable mongod Installing Robo 3T Michael recommended Robo 3t so I decided to give it a try. I went to their download page and selected the linux version. My connection at home is terrible, so I try not to download anything through the browser. I copied the link and used wget instead. cd ~/Downloads wget -c https://download-test.robomongo.org/linux/robo3t-1.3.1-linux-x86_64-7419c406.tar.gz Once it had finished downloading, I extracted the file to my home directory: mkdir ~/robo3t tar -xvzf robo3t-1.3.1-linux-x86_64-7419c406.tar.gz -C ~/robo3t Adding a custom menu entry I like to add all of my programs to the &#34;start&#34; menu, so I then did the following: cd ~/robo3t wget https://robomongo.org/static/robomongo-128x128-129df2f1.png -O robomongo.png ln -s robo3t-1.3.1-linux-x86_64-7419c406/bin/robo3t robo3t Right-click the Mint start button Click on Configure... Click on the Menu button from the dialog window and then click on Open the menu editor From the Main Menu widget, click on the Programming section and then click on the New Item button Fill in the Launcher Properties. Select the robomongo.png image that we downloaded previously. Give it a Name, Robo 3T. For the Command select the symlink that we created previously. Enter whatever you want under Comment and click OK. Close all of the open dialogs. Admire you&#39;re awesomeness Before you can start using Robo 3T, you will have to get to the point of the tutorial where you add a user. Once you&#39;ve made an entry, go ahead and start it Robo 3T. You will be presented with a MongoDB Connections dialog. Click on the Create link to open up the Connection Settings dialog. For the Name enter snake_bnb, the name of the database that was created in the tutorial and Save. Click on the Connect button to access it. Conclusion Quite a few steps to get here, but now I am setup and ready to continue on with the course and hopefully you will be too!", 
            "tags": "Database", 
            "loc": "https://clamytoe.github.io/articles/2020/Mar/06/how-to-install-mongodb-on-linux"
        },
        {
            "title": "Playing around with adding plugins to Pelican", 
            "text":"Some parts of my blog were looking pretty blah Math syntax I&#39;ve been tweaking my blog like crazy. Just making minor changes here and there. I wanted to make things look a little better. For instance, for my rescaling article, I had the following mathematical syntax: ScaledQuantity = (ActualQuantity-MinQuantity)/(MaxQuantity-MinQuantity) What the hell is that? That looks horrible! I know that markdown supports Latex, so I looked and found this awesome resource: Writing Mathematic Formulars in Markdown ScaledQuantity = \frac{ActualQuantity-MinQuantity}{MaxQuantity-MinQuantity} Um, not quite there yet. Something was up. I searched to see if Pelican had any plugins for rendering math and sure enough, found that pelican-plugins included render_math. I followed the instructions and cloned the repo into my blog directory. Probably should have dropped it somewhere outside of it, but I added it to my .gitignore and it&#39;s fine... I added the following to my pelicanconf.py file: PLUGIN_PATHS = [&#39;./pelican-plugins&#39;] PLUGINS = [&#39;render_math&#39;] I tried the previous code once again and was still getting the same results. After some more reading I found that you have to enclose the mathematical equation within double $. $$ScaledQuantity = \frac{ActualQuantity-MinQuantity}{MaxQuantity-MinQuantity}$$ NICE! Markdown tables My original tables were so bland that it was almost hard to tell that they were even tables! Unfortunately I didn&#39;t save a screenshot of it, so I can&#39;t show you what they looked like, but I can definitely show you the end result! Thanks to mockaroo I was able to generate some mock data relatively quickly. id first_name last_name email gender ip_address 1 Odilia O&#39;Meara oomeara0@yahoo.co.jp Female 244.53.86.185 2 Marcelo Tunna mtunna1@netvibes.com Male 128.140.17.56 3 Farris Roston froston2@ucla.edu Male 111.104.78.209 4 Gene Benzies gbenzies3@nymag.com Male 67.169.248.21 5 Ellsworth Goodered egoodered4@hud.gov Male 227.48.46.133 6 Jan Garnsworth jgarnsworth5@amazon.de Male 138.13.211.142 7 Robby Rosenstengel rrosenstengel6@chron.com Female 105.76.137.198 8 Granthem Rymer grymer7@yolasite.com Male 15.60.66.25 9 Claire Stuther cstuther8@salon.com Female 5.36.242.109 10 Maggy Jearum mjearum9@npr.org Female 179.12.188.75 CSS changes I hope it doesn&#39;t bite me in the butt later on, but I&#39;m forcing the table headers into uppercase. In case anyone is curious, this are the styles that I added to the theme: table { border-collapse: collapse; margin-left: auto; margin-right: auto; width: 90%; } td, th { border: 1px solid #ddd; padding: 8px; } tr:nth-child(even){background-color: #f2f2f2;} tr:hover {background-color: #ddd;} th { padding-top: 12px; padding-bottom: 12px; text-transform: uppercase; font-weight: bold; background-color: #607D8B; color: white; } .math { font-size: medium; } The default math syntax rendering was kind of small, so I changed the font-size to medium. On a side note I noticed that some of my changes wouldn&#39;t take effect until after I removed the pycache and .pytest_cache directories. In order to automate this, I modified my Makefile&#39;s clean code to the following: clean: [ ! -d $(OUTPUTDIR) ] || rm -rf $(OUTPUTDIR) rm -rf __pycache__ rm -rf .pytest_cache Conclusion This web development stuff is pretty complex. There are lots of moving parts, so I give all of my fellow web developers a high-five for being so awesome! I can see how this can be pretty overwhelming if you&#39;re new to this, but just keep at it and you&#39;ll get there. This old dog can still learn some new tricks! if (!document.getElementById(&#39;mathjaxscript_pelican_#%@#$@#&#39;)) { var align = &#34;left&#34;, indent = &#34;0em&#34;, linebreak = &#34;true&#34;; if (true) { align = (screen.width", 
            "tags": "Blog", 
            "loc": "https://clamytoe.github.io/articles/2020/Mar/03/pelican-plugins"
        },
        {
            "title": "Finally getting the hang of working with Pelican!", 
            "text":"Stumbling into a nice Pelican workflow If you&#39;ve seen my source repo for this site, you know that I followed Erik O&#39;Shaughnessy&#39;s Run your blog on GitHub Pages with Python tutorial. It&#39;s a great tutorial, I specifically love his one weird trick, but it leaves so many unanswered questions. Go read it now if you haven&#39;t and we&#39;ll pick up where he leaves off. Luckily he does provide the link to the official documentation. It was through that link that I found Pelican&#39;s tutorials repo. Specifically Matt Makai&#39;s introductory tutorial. I&#39;ll admit, that I only skimmed over it, it&#39;s kind of long. I was looking for anything that would jump out at me. What caught my eye was how simple it all was to automate things with make! I took a quick look at mine and saw what commands were defined. Makefile for a pelican Web site Usage: make html (re)generate the web site make clean remove the generated files make regenerate regenerate files upon modification make publish generate using production settings make serve [PORT=8000] serve site at http://localhost:8000 make serve-global [SERVER=0.0.0.0] serve (as root) to :80 make devserver [PORT=8000] serve and regenerate together make ssh_upload upload the web site via SSH make rsync_upload upload the web site via rsync+ssh make github upload the web site via gh-pages Set the DEBUG variable to 1 to enable debugging, e.g. make DEBUG=1 html Set the RELATIVE variable to 1 to enable relative urls Looking at the Makefile source is where I noticed that for local development, it just uses the pelicanconf.py script, but for publishing it uses publishconf.py. Makefile[Lines 8-9] CONFFILE=$(BASEDIR)/pelicanconf.py PUBLISHCONF=$(BASEDIR)/publishconf.py Looking at publishconf.py I saw that it actually imports pelicanconf.py and then overrides some of the variables. publishconf.py[Lines 12-19] from pelicanconf import * # If your site is available via HTTPS, make sure SITEURL begins with https:// SITEURL = &#34;https://clamytoe.github.io&#34; RELATIVE_URLS = False FEED_ALL_ATOM = &#34;feeds/all.atom.xml&#34; CATEGORY_FEED_ATOM = &#34;feeds/{slug}.atom.xml&#34; AHA! This is were I had a eurika moment! I had noticed a problem with my site. Whenever I clicked on the header link, instead of taking me back to the home page it would just reload whatever page I was on. I was able to get around that by just specifying the SITE_URL variable in pelicanconf.py. Unfortunately, that broke testing the blog locally because all the links would point to the live site on GitHub! What I&#39;m trying to say here is that in I was able to resolve both of these issues by making the following changes. pelicanconf.py[Lines 16-16] SITEURL = &#34;&#34; publishconf.py[Lines 12-12] from pelicanconf import * Another issue that I was having was that I couldn&#39;t figure out how to get my favicon.ico to be treated as a static file and automatically dumped into the output directory. My solution had been to write a little bash script to copy it over for me, but that was kind of tedious. But now that I was going to use the Makefile I decided to automate it in there! I added the following lines to it: Makefile[Lines 10-10] FAVICON=$(INPUTDIR)/static/favicon.ico Then after the html, regenerate, and publish commands, I added: Makefile[Lines 44-46] html: $(PELICAN) $(INPUTDIR) -o $(OUTPUTDIR) -s $(CONFFILE) $(PELICANOPTS) cp $(FAVICON) $(OUTPUTDIR) Makefile[Lines 53-55] regenerate: $(PELICAN) -r $(INPUTDIR) -o $(OUTPUTDIR) -s $(CONFFILE) $(PELICANOPTS) cp $(FAVICON) $(OUTPUTDIR) Makefile[Lines 79-81] publish: $(PELICAN) $(INPUTDIR) -o $(OUTPUTDIR) -s $(PUBLISHCONF) $(PELICANOPTS) cp $(FAVICON) $(OUTPUTDIR) NOTE: I had initially added that to all of the commands, but the ones that run the server, don&#39;t actually get to that step. When I Ctrl+C out of it, it just exists... New workflow With that all set, things are now much easier and make more sense. What I would recommend, is to run the make clean command and commit it to your content branch. Now you will have a clean slate to start with. You can now add any new content and do the following commands: git add . git commit -m &#34;Your description...&#34; git push origin content NOTE: Of course, only push your files when you&#39;re ready to, but you get the idea. Now you&#39;re ready to generate the actual site, here&#39;s how that&#39;s now done. Generate the site If you just want to generate the site this is the command that you want: make html Then you can either run the Pelican server or the Python one. Pelican server pelican -r --listen Python server cd output python -m http.server Both of those will make the site accessible at http://localhost:8000 Generate site and preview Now, if you know that you will be wanting to preview your site, a much better way is to use this command: make devserver Not only will this generate the site, but will also start the Pelican server automagically for you! This option comes in handy when you are tweaking your site&#39;s theme. I wanted to change the colors on mine and doing it like this automatically detected the changes and served them up. Publish the site This command generates the site using the publishconf.py script, so if you specified your site&#39;s url in there, it will add it to the generated html pages. It&#39;s nice for making sure all is working correctly and enabling your Google Analytics; if you&#39;re into that sort of thing. make publish Publish and push to github Now, we&#39;re cooking with Crisco! This command will generate the final site using publishconf.py, merge the output into your master branch, and push it up the hubs; all in one step! make github Cleaning up Now that you&#39;ve pushed to the hubs, removed the generated files: make clean If you run git status, you should see that there are no changes and that you are ready to add more content. Nice! Conclusion This was a great learning experience for me. Not only did I update the color scheme of my site, I also fixed some annoying issues that I was having. Now I don&#39;t have to look up any ghp-import ... command and things just got a heck of a lot more pleasant. In summary: touch content/posts/new-blog-post.md vi $_ # write the blog content git status git add . git commit -m &#34;New blog post.&#34; git push origin content make github make clean On a side note I was also having a weird problem with my search feature. I had to remove the machine code from my cryptography blog post because it was completely screwing up the JavaScript. Once I got that working, I then noticed that whenever I tried to do a search from any of the category pages, that it was looking for /category/search.html. That page doesn&#39;t exists, so I was baffled as to why that was going on. I took a look at the pelican-mg theme&#39;s Jinja templates and found the issue in base.html. I simply had to add {{ SITEURL }} in the action part of the form: &lt;form class=&#34;uk-search&#34; action=&#34;{{ SITEURL }}/search.html&#34; data-uk-search&gt; Now it works beautifully! Of course, with me being an upstanding netcitizen, I submitted a pull request to fix the issue :).", 
            "tags": "Blog", 
            "loc": "https://clamytoe.github.io/articles/2020/Feb/28/pelican"
        },
        {
            "title": "Pytest fixtures with tear down", 
            "text":"Pytest fixtures with tear down code Setting up pytest fixtures with teardown code Today after listening to Brian Okken&#39;s Test &amp; Code podcast with Anthony Shaw, I was reminded that I wanted to install Anthony&#39;s Python Security Plugin for JetBrain&#39;s PyCharm IDE. That was a breeze to install and it just worked out of the box. I fired it up and it automatically checked my code and called it good. I then started to write some tests and while checking a password, it alerted me to an issue. It made a suggestion to fix it, so I accepted and it updated my code and even added the proper import statement! FROM: assert dummy.password == &#34;admin&#34; TO: from secrets import compare_digest import pytest from passlock.entry import Entry @pytest.fixture(scope=&#34;module&#34;) def dummy(): return Entry(&#34;router&#34;, &#34;http://192.168.2.1&#34;, &#34;admin&#34;, &#34;admin&#34;) def test_entry(dummy): assert dummy.name == &#34;router&#34; assert dummy.url == &#34;http://192.168.2.1&#34; assert dummy.username == &#34;admin&#34; assert compare_digest(dummy.password, &#34;admin&#34;) Although, this is just a dummy password for testing, it doesn&#39;t hurt to build up some good habits! On to the fixture tear down This is when I got to the part where I had to test the creation of my private and public keys. Since I was creating them for testing and didn&#39;t want them around afterwards, I decided that I needed to make them go away after the tests were done. I was already using fixtures so that I didn&#39;t have to recreate the instances of my classes for each test; generating the keys take a bit of time! I went crazy an opted to make them future proof with 4096-bits... The challenge was figuring out how to tear them down. I did some initial searches and was coming up blank. I then looked up the pytest guru, Brian&#39;s blog about the topic, but his examples were too simplistic for what I was trying to do. All they demonstrated was how to print a message, it didn&#39;t actually show how to return anything, and then have it torn down afterwards. Brian&#39;s example: from __future__ import print_function import pytest @pytest.fixture(scope=&#39;module&#39;) def resource_a_setup(request): print(&#39;\nresources_a_setup()&#39;) def resource_a_teardown(): print(&#39;\nresources_a_teardown()&#39;) request.addfinalizer(resource_a_teardown) def test_1_that_needs_resource_a(resource_a_setup): print(&#39;test_1_that_needs_resource_a()&#39;) def test_2_that_does_not(): print(&#39;\ntest_2_that_does_not()&#39;) def test_3_that_does(resource_a_setup): print(&#39;\ntest_3_that_does()&#39;) I ended up reading the actual pytest documentation; who would have thunk?! I&#39;ll do you guys a solid and cut out the noise and show you what I did: import pytest @pytest.fixture(scope=&#34;module&#34;) def custom_locker(): v = Vault(&#34;.toe&#34;, &#34;tlock&#34;) yield v v.plock.unlink() v.pub.unlink() v.base.rmdir() def test_vault_custom(custom_locker): assert custom_locker.loc == &#34;.toe&#34; assert custom_locker.key_name == &#34;tlock&#34; Setting the scope of the fixture to module makes it so that it doesn&#39;t actually do the tearing down until after all of the tests are completed. Perfect! The variables in the Vault instance are Path objects, so it was simple enough to just unlink() the files and then rmdir() the directory after it&#39;s been emptied. Of course, I tried removing the directory first, but it wasn&#39;t having any of that until it was empty...", 
            "tags": "Python", 
            "loc": "https://clamytoe.github.io/articles/2020/Feb/19/pytest-fixtures"
        },
        {
            "title": "Into the cryptography rabbit hole", 
            "text":"Venture Into Cryptography with PyCryptodome Learning about how to encrypt files As dumb as it is, I have an unsecured text file that I use to keep track of all my username and passwords for all of the sites that I frequent. In order to not be so &#34;hackable&#34;, I&#39;ve decided to encrypt the file. I had recently written a couple of coding challenges for Pybites Code Challenges site, using the cryptography module. One was a coding challenge and the other a testing one. Unfortunately, that module is NOT part of Python&#39;s Standard Library! I didn&#39;t specifically install it, but it seems to come pre-installed with Anaconda, which I use. I was looking through all of the modules that I had, when I came across the cryptography one. That&#39;s when I first got the idea for the challenges. It started as a single challenge, but I really liked how the tests came out and decided to split it up into coding and testing bites. I pushed them to the Pybites Github private repo and it sat there for a bit before Bob Belderbos decided to add them. That&#39;s when the problems started! He discovered that the module was not available so he installed it. It worked perfectly for the coding challenge, but for the testing one, when the call to the Pytest/Mutpy instance is made, it looses the path to the module! We were discussing the issue on the Pybites Slack channel when Mike Driscoll the creator of The Mouse vs Python, mentioned the PyCryptodome module. He initially thought that the problem was with installing the cryptography module. In the end, Bob was not able to figure out how to get it to work, so the challenge had to be removed from the platform. Regardless, I was intrigued by pycryptodome, so I started to look into how it worked. It seemed pretty cool, so that&#39;s when I came up with the idea of encrypting my password file. It took a little bit of work, but I was able to encrypt the file into a binary. The problem came when I started to try and retrieve the data. The module complained about the data being too large! I decided to create an encrypted binary for each entry. So far that&#39;s worked, but now I have to figure out how to scan the directory and list the ones that are available in order to be able to retrieve/update them. I&#39;ve been using the logging module as well, so now I have to figure out how to do some log rotation to keep from taking up too much drive space. I might even play around with creating a UI for it, to make it easier to use. Since I used my toepack Cookiecutter template, it&#39;s a package. It&#39;s gotten big enough that I&#39;ve moved the two classes, (Entry, Vault) into their own files. It works out pretty good because the app.py file now only contains: from .entry import Entry from .vault import Vault, logger def main(): logger.debug(&#34;Entering main.&#34;) ip = Entry(&#34;ip&#34;, &#34;http://192.168.2.1&#34;, &#34;admin&#34;, &#34;admin&#34;) v = Vault() v.encrypt_file(ip) v.decrypt_file(ip.name) if __name__ == &#34;__main__&#34;: logger.debug(&#34;Running as a module.&#34;) main() Separating the code like this will come in handy when it comes to either creating a Click CLI interface or a GUI one. The log file for that run looks like this: 2020-02-13 14:05:17,812 - [INFO] - root - Creating vault: /home/mohh/Documents/.passlock/ip.bin 2020-02-13 14:05:17,812 - [INFO] - root - Importing public key: plock.pub 2020-02-13 14:05:17,812 - [INFO] - root - Public key accessed: /home/mohh/.passlock/plock.pub 2020-02-13 14:05:17,815 - [INFO] - root - Generating random byte for session key 2020-02-13 14:05:17,815 - [INFO] - root - Generating encrypted session key 2020-02-13 14:05:17,819 - [INFO] - root - Generating AES cipher 2020-02-13 14:05:17,820 - [INFO] - root - Encrypting data to create cipher text 2020-02-13 14:05:17,820 - [INFO] - root - Writing cipher text to: ip.bin 2020-02-13 14:05:17,820 - [WARNING] - root - /home/mohh/Documents/.passlock/ip.bin already exists! 2020-02-13 14:05:17,820 - [INFO] - root - Successfully wrote to: /home/mohh/Documents/.passlock/ip.bin 2020-02-13 14:05:17,821 - [INFO] - root - Opening file for reading: /home/mohh/Documents/.passlock/ip.bin 2020-02-13 14:05:17,821 - [INFO] - root - Importing private key: plock 2020-02-13 14:05:17,821 - [INFO] - root - Private key accessed: /home/mohh/.passlock/plock 2020-02-13 14:05:18,150 - [INFO] - root - Extracting encrypted session key 2020-02-13 14:05:18,151 - [INFO] - root - Generating RSA cipher key from imported private key 2020-02-13 14:05:18,151 - [INFO] - root - Decrypting extracted session key 2020-02-13 14:05:18,171 - [INFO] - root - Session key was successfully restored 2020-02-13 14:05:18,171 - [INFO] - root - Generating AES cipher from session key 2020-02-13 14:05:18,172 - [INFO] - root - Decrypting and verifying cipher text 2020-02-13 14:05:18,172 - [INFO] - root - Closing: ip.bin 2020-02-13 14:05:18,172 - [INFO] - root - Generating new Entry object from decrypted data 2020-02-13 14:05:18,172 - [INFO] - root - Returning decrypted text for: ip Not sure if that&#39;s too much information but logging each step in the process really comes in handy when trying to figure out issues at work. I&#39;ve tried to keep all sensitive data out of it unless the logging is switched to debug. Retrieving the encrypted data looks like this: Successfully created: /home/mohh/Documents/.passlock/ip.bin [ip] INFO: http://192.168.2.1 USER: admin PASS: admin NOTE: These are not real username and passwords!", 
            "tags": "Python", 
            "loc": "https://clamytoe.github.io/articles/2020/Feb/14/pycryptodome"
        },
        {
            "title": "Rescaling values for DataScience", 
            "text":"Scaling values Today while reading Data Science Algorithms in a Week, from packt, I came across the concept of rescaling values so that when measuring their distances they would be more relevant. The dataset consisted of &#34;House Ownership&#34;: Age Annual income in USD House ownership status 23 50,000 Non-owner 37 34,000 Non-owner 20 100,000 Owner 35 130,000 Owner etc.. The aim being to predict whether a person that is 50 years old with an income of $80,000, would own a home so that he could be targeted for home insurance. k-Nearest Neighbor&#39;s are currently being covered and for this exercise a k = 1 is to be used. Using either a Euclidean or Manhattan distance wouldn&#39;t matter because the distances between these values are too great. In comes rescaling! The formula use is: $$ScaledQuantity = \frac{ActualQuantity-MinQuantity}{MaxQuantity-MinQuantity}$$ So for this dataset, both the Age and the Annual income wound have to be adjusted. $$ScaledAge = \frac{ActualAge-MinAge}{MaxAge-MinAge}$$ $$ScaledIncome = \frac{ActualIncome-MinIncome}{MaxIncome-MinIncome}$$ After scaling, the adjusted dataset would look something like this: Age Scaled age Annual income in USD Scaled annual income House ownership status 23 09375 50,000 2 Non-owner 37 53125 34,000 4 Non-owner 20 0 100,000 7 Owner 35 46875 130,000 1 Owner 50 9375 80,000 5 ? Now a 1-NN algorithm with a Euclidean metric could easily be used to find out if the last person is more than likely to own a home. Without the rescaling, the algorithm would have yielded different results. Keeping it short today, but hopefully it was a helpful tip! if (!document.getElementById(&#39;mathjaxscript_pelican_#%@#$@#&#39;)) { var align = &#34;left&#34;, indent = &#34;0em&#34;, linebreak = &#34;true&#34;; if (true) { align = (screen.width", 
            "tags": "DataScience", 
            "loc": "https://clamytoe.github.io/articles/2020/Feb/13/rescaling-values"
        },
        {
            "title": "This is my first post here", 
            "text":"Getting my feet wet with this blogging stuff It&#39;s not much to look at, but my goal is to show what I&#39;m learning as I go. There&#39;s no real &#34;topic&#34; but it will mostly be about what I&#39;m working on and what I have to learn to get it done. Hope that it&#39;s of interest to someone...", 
            "tags": "Blog", 
            "loc": "https://clamytoe.github.io/articles/2020/Feb/12/initial-post"
        },
        {
            "title": "About", 
            "text":"Hi, I&#39;m Martin, a.k.a clamytoe, and I am the author of these &#34;ramblings&#34;. Will flesh this out later!", 
            "tags": "pages", 
            "loc": "https://clamytoe.github.io/pages/about"
        }        
    ]
}