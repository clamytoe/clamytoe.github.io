{
    "pages": [
        {
            "title": "Finally getting the hang of working with Pelican!", 
            "text":"Finally getting the hang of working with Pelican! If you&#39;ve seen my source repo for this site, you know that I followed Erik O&#39;Shaughnessy&#39;s Run your blog on GitHub Pages with Python tutorial. It&#39;s a great tutorial, I specifically love his one weird trick, but it leaves so many unanswered questions. Go read it now if you haven&#39;t and we&#39;ll pick up where he leaves off. Luckily he does provide the link to the official documentation. It was through that link that I found Pelican&#39;s tutorials repo. Specifically Matt Makai&#39;s introductory tutorial. I&#39;ll admit, that I only skimmed over it, it&#39;s kind of long. I was looking for anything that would jump out at me. What caught my eye was how simple it all was to automate things with make! I took a quick look at mine and saw what commands were defined. make Makefile for a pelican Web site Usage: make html (re)generate the web site make clean remove the generated files make regenerate regenerate files upon modification make publish generate using production settings make serve [PORT=8000] serve site at http://localhost:8000 make serve-global [SERVER=0.0.0.0] serve (as root) to :80 make devserver [PORT=8000] serve and regenerate together make ssh_upload upload the web site via SSH make rsync_upload upload the web site via rsync+ssh make github upload the web site via gh-pages Set the DEBUG variable to 1 to enable debugging, e.g. make DEBUG=1 html Set the RELATIVE variable to 1 to enable relative urls Looking at the Makefile source is where I noticed that for local development, it just uses the pelicanconf.py script, but for publishing it uses publishconf.py. Looking at publishconf.py I saw that it actually imports pelicanconf.py and then overrides some of the variables. AHA! This is were I had a eurika moment! I had noticed a problem with my site. Whenever I clicked on the header link, instead of taking me back to the home page it would just reload whatever page I was on. I was able to get around that by just specifying the SITE_URL variable in pelicanconf.py. Unfortunately, that broke testing the blog locally because all the links would point to the live site on GitHub! What I&#39;m trying to say here is that in I was able to resolve both of these issues by making the following changes. pelicanconf.py: SITEURL = &#34;&#34; publishconf.py: SITEURL = &#34;https://clamytoe.github.io&#34; Another issue that I was having was that I couldn&#39;t figure out how to get my favicon.ico to be treated as a static file and automatically dumped into the output directory. My solution had been to write a little bash script to copy it over for me, but that was kind of tedious. But now that I was going to use the Makefile I decided to automate it in there! I added the following lines to it: FAVICON=$(INPUTDIR)/static/favicon.ico Then after the html, regenerate, and publish commands, I added: cp $(FAVICON) $(OUTPUTDIR) NOTE: I had initially added that to all of the commands, but the ones that run the server, don&#39;t actually get to that step. When I Ctrl+C out of it, it just exists... New workflow With that all set, things are now much easier and make more sense. What I would recommend, is to run the make clean command and commit it to your content branch. Now you will have a clean slate to start with. You can now add any new content and do the following commands: git add . git commit -m &#34;Your description...&#34; git push origin content NOTE: Of course, only push your files when you&#39;re ready to, but you get the idea. Now you&#39;re ready to generate the actual site, here&#39;s how that&#39;s now done. Generate the site If you just want to generate the site this is the command that you want: make html Then you can either run the Pelican server or the Python one. Pelican server pelican --listen Python server cd output python -m http.server Both of those will make the site accessible at http://localhost:8000 Generate site and preview Now, if you know that you will be wanting to preview your site, a much better way is to use this command: make devserver Not only will this generate the site, but will also start the Pelican server automagically for you! This option comes in handy when you are tweaking your site&#39;s theme. I wanted to change the colors on mine and doing it like this automatically detected the changes and served them up. Publish the site This command generates the site using the publishconf.py script, so if you specified your site&#39;s url in there, it will add it to the generated html pages. It&#39;s nice for making sure all is working correctly and enabling your Google Analytics; if you&#39;re into that sort of thing. make publish Publish and push to github Now, we&#39;re cooking with Crisco! This command will generate the final site using publishconf.py, merge the output into your master branch, and push it up the hubs; all in one step! make github Cleaning up Now that you&#39;ve pushed to the hubs, removed the generated files: make clean If you run git status, you should see that there are no changes and that you are ready to add more content. Nice! Conclusion This was a great learning experience for me. Not only did I update the color scheme of my site, I also fixed some annoying issues that I was having. Now I don&#39;t have to look up any ghp-import ... command and things just got a heck of a lot more pleasant. In summary: touch content/posts/new-blog-post.md vi $_ # write the blog content git status git add . git commit -m &#34;New blog post.&#34; git push origin content make github make clean On a side note... I was also having a weird problem with my search feature. I had to remove the machine code from my cryptography blog post because it was completely screwing up the JavaScript. Once I got that working, I then noticed that whenever I tried to do a search from any of the category pages, that it was looking for /category/search.html. That page doesn&#39;t exists, so I was baffled as to why that was going on. I took a look at the pelican-mg theme&#39;s Jinja templates and found the issue in base.html. I simply had to add {{ SITEURL }} in the action part of the form: &lt;form class=&#34;uk-search&#34; action=&#34;{{ SITEURL }}/search.html&#34; data-uk-search&gt; Now it works beautifully! Of course, with me being an upstanding netcitizen, I submitted a pull request to fix the issue :).", 
            "tags": "Pelican", 
            "loc": "https://clamytoe.github.io/pelican.html"
        },
        {
            "title": "Pytest fixtures with tear down", 
            "text":"Pytest fixtures with tear down code Today after listening to Brian Okken&#39;s Test &amp; Code podcast with Anthony Shaw, I was reminded that I wanted to install Anthon&#39;s Python Security Plugin for JetBrain&#39;s PyCharm IDE. That was a breeze to install and it just worked out of the box. I fired it up and it automatically checked my code and called it good. I then started to write some tests and while checking a password, it alerted me to an issue. It made a suggestion to fix it, so I accepted and it updated my code and even added the proper import statement! FROM: assert dummy.password == &#34;admin&#34; TO: from secrets import compare_digest import pytest from passlock.entry import Entry @pytest.fixture(scope=&#34;module&#34;) def dummy(): return Entry(&#34;router&#34;, &#34;http://192.168.2.1&#34;, &#34;admin&#34;, &#34;admin&#34;) def test_entry(dummy): assert dummy.name == &#34;router&#34; assert dummy.url == &#34;http://192.168.2.1&#34; assert dummy.username == &#34;admin&#34; assert compare_digest(dummy.password, &#34;admin&#34;) Although, this is just a dummy password for testing, it doesn&#39;t hurt to build up some good habits! On to the fixture tear down This is when I got to the part where I had to test the creation of my private and public keys. Since I was creating them for testing and didn&#39;t want them around afterwards, I decided that I needed to make them go away after the tests were done. I was already using fixtures so that I didn&#39;t have to recreate the instances of my classes for each test; generating the keys take a bit of time! I went crazy an opted to make them future proof with 4096-bits... The challenge was figuring out how to tear them down. I did some initial searches and was coming up blank. I then looked up the pytest guru, Brian&#39;s blog about the topic, but his examples were too simplistic for what I was trying to do. All they demonstrated was how to print a message, it didn&#39;t actually show how to return anythin, and then have it torn down afterwards. Brian&#39;s example: from __future__ import print_function import pytest @pytest.fixture(scope=&#39;module&#39;) def resource_a_setup(request): print(&#39;\nresources_a_setup()&#39;) def resource_a_teardown(): print(&#39;\nresources_a_teardown()&#39;) request.addfinalizer(resource_a_teardown) def test_1_that_needs_resource_a(resource_a_setup): print(&#39;test_1_that_needs_resource_a()&#39;) def test_2_that_does_not(): print(&#39;\ntest_2_that_does_not()&#39;) def test_3_that_does(resource_a_setup): print(&#39;\ntest_3_that_does()&#39;) I ended up reading the actual pytest documentation, who would have thunk?! I&#39;ll do you guys a solid and cut out the noise and show you what I did: import pytest @pytest.fixture(scope=&#34;module&#34;) def custom_locker(): v = Vault(&#34;.toe&#34;, &#34;tlock&#34;) yield v v.plock.unlink() v.pub.unlink() v.base.rmdir() def test_vault_custom(custom_locker): assert custom_locker.loc == &#34;.toe&#34; assert custom_locker.key_name == &#34;tlock&#34; Setting the scope of the fixture to module makes it so that it doesn&#39;t actually do the tearing down until after all of the tests are completed. Perfect! The variables in the Vault instance are Path objects, so it was simple enough to just unlink() the files and then rmdir() the directory after it&#39;s been emptied. Of course, I tried removing the directory first, but it wasn&#39;t having any of that until it was empty...", 
            "tags": "Pytest", 
            "loc": "https://clamytoe.github.io/pytest-fixtures.html"
        },
        {
            "title": "Venture Into Cryptography with PyCryptodome!", 
            "text":"Into the cryptography rabbit hole! As dumb as it is, I have an unsecure text file that I use to keep track of all my username and passwords for all of the sites that I frequent. In order to not be so &#34;hackable&#34;, I&#39;ve decided to encrypt the file. I had recently written a couple of coding challenges for Pybites Code Challenges site, using the cryptography module. One was a coding challenge and the other a testing one. Unfortunately, that module is NOT part of Python&#39;s Standard Library! I didn&#39;t specifically install it, but it seems to come pre-installed with Anaconda, which I use. I was looking through all of the modules that I had, when I came across the cryptography one. That&#39;s when I first got the idea for the challenges. It started as a single challenge, but I really liked how the tests came out and decided to split it up into coding and testing bites. I pushed them to the Pybites Github private repo and it sat there for a bit before Bob Belderbos decided to add them. Tha&#39;s when the problems started! He discovered that the module was not available so he installed it. It worked perfectly for the coding challenge, but for the testing one, when the call to the Pytest/Mutpy instance is made, it loosed the path to the module! We were discussing the issue on the Pybites Slack channel when Mike Driscoll the creator of The Mouse vs Python, mentioned the PyCryptodome module. He initially thought that the problem was with installing the cryptography module. In the end, Bob was not able to figure out how to get it to work, so the challenge had to be removed from the platform. Regardless, I was intrigued by pycryptodome, so I started to look into how it worked. It seemed pretty cool, so that&#39;s when I came up with the idea of encrypting my password file. It took a little bit of work, but I was able to encrypt the file into a binary. The problem came when I started to try and retrieve the data. The module complained about the data being too large! I decided to create an encrypted binary for each entry. So far that&#39;s worked, but now I have to figure out how to scan the directory and list the ones that are available in order to be able to retrieve/update them. I&#39;ve been using the logging module as well, so now I have to figure out how to do some log rotation to keep from taking up too much drive space. I might even play around with creating a UI for it, to make it easier to use. Since I used my toepack Cookiecutter template, it&#39;s a package. It&#39;s gotten big enough that I&#39;ve moved the two classes, (Entry, Vault) into their own files. It works out pretty good because the app.py file now only contains: from .entry import Entry from .vault import Vault, logger def main(): logger.debug(&#34;Entering main.&#34;) ip = Entry(&#34;ip&#34;, &#34;http://192.168.2.1&#34;, &#34;admin&#34;, &#34;admin&#34;) v = Vault() v.encrypt_file(ip) v.decrypt_file(ip.name) if __name__ == &#34;__main__&#34;: logger.debug(&#34;Running as a module.&#34;) main() Seperating the code like this will come in handy when it comes to either creating a Click CLI interface or a GUI one. The log file for that run looks like this: 2020-02-13 14:05:17,812 - [INFO] - root - Creating vault: /home/mohh/Documents/.passlock/ip.bin 2020-02-13 14:05:17,812 - [INFO] - root - Importing public key: plock.pub 2020-02-13 14:05:17,812 - [INFO] - root - Public key accessed: /home/mohh/.passlock/plock.pub 2020-02-13 14:05:17,815 - [INFO] - root - Generating random byte for session key 2020-02-13 14:05:17,815 - [INFO] - root - Generating encrypted session key 2020-02-13 14:05:17,819 - [INFO] - root - Generating AES cipher 2020-02-13 14:05:17,820 - [INFO] - root - Encrypting data to create cipher text 2020-02-13 14:05:17,820 - [INFO] - root - Writing cipher text to: ip.bin 2020-02-13 14:05:17,820 - [WARNING] - root - /home/mohh/Documents/.passlock/ip.bin already exists! 2020-02-13 14:05:17,820 - [INFO] - root - Successfully wrote to: /home/mohh/Documents/.passlock/ip.bin 2020-02-13 14:05:17,821 - [INFO] - root - Opening file for reading: /home/mohh/Documents/.passlock/ip.bin 2020-02-13 14:05:17,821 - [INFO] - root - Importing private key: plock 2020-02-13 14:05:17,821 - [INFO] - root - Private key accessed: /home/mohh/.passlock/plock 2020-02-13 14:05:18,150 - [INFO] - root - Extracting encrypted session key 2020-02-13 14:05:18,151 - [INFO] - root - Generating RSA cipher key from imported private key 2020-02-13 14:05:18,151 - [INFO] - root - Decrypting extracted session key 2020-02-13 14:05:18,171 - [INFO] - root - Session key was successfully restored 2020-02-13 14:05:18,171 - [INFO] - root - Generating AES cipher from session key 2020-02-13 14:05:18,172 - [INFO] - root - Decrypting and verifying cipher text 2020-02-13 14:05:18,172 - [INFO] - root - Closing: ip.bin 2020-02-13 14:05:18,172 - [INFO] - root - Generating new Entry object from decrypted data 2020-02-13 14:05:18,172 - [INFO] - root - Returning decrypted text for: ip Not sure if that&#39;s too much information but logging each step in the process really comes in handy when trying to figure out issues at work. I&#39;ve tried to keep all sensitive data out of it unless the logging is switched to debug. Retrieving the encrypted data looks like this: Successfully created: /home/mohh/Documents/.passlock/ip.bin [ip] INFO: http://192.168.2.1 USER: admin PASS: admin NOTE: These are not real username and passwords!", 
            "tags": "Cryptography", 
            "loc": "https://clamytoe.github.io/pycryptodome.html"
        },
        {
            "title": "Initial Post for my Ramblings of an autodiadact Blog", 
            "text":"Getting my feet wet with this blogging stuff! This is my first post here. It&#39;s not much to look at, but my goal is to show what I&#39;m learning as I go. There&#39;s no real &#34;topic&#34; but it will mostly be about what I&#39;m working on and what I have to learn to get it done. Hope that it&#39;s of interest to someone...", 
            "tags": "General", 
            "loc": "https://clamytoe.github.io/initial-post.html"
        },
        {
            "title": "Rescaling Values", 
            "text":"Scaling Values Today while reading Data Science Algorithms in a Week, from packt, I came across the concept of rescaling values so that when measuring their distances they would be more relevant. The dataset consisted of &#34;House Ownership&#34;: Age Annual income in USD House ownership status 23 50,000 Non-owner 37 34,000 Non-owner 20 100,000 Owner 35 130,000 Owner etc The aim being to predict whether a person that is 50 years old with an income of $80,000, would own a home so that he could be targeted for home insurance. k-Nearest Neighbor&#39;s are currently being covered and for this exercise a k = 1 is to be used. Using either a Euclidean or Manhattan distance wouldn&#39;t matter because the distances between these values are too great. In comes rescalling! The formula use is: ScaledQuantity = (ActualQnatity-MinQuantity)/(MaxQuantity-MinQuantity) So for this dataset, both the Age and the Annual income wound have to be adjusted. ScaledAge = (ActualAge-MinAge)/(MaxAge-MinAge) ScaledIncome = (ActualIncome-MinIncome)/(MaxIncome-MinIncome) After scaling, the adjusted dataset would look something like this: Age Scaled age Annual income in USD Scaled annual income House ownership status 23 09375 50,000 2 Non-owner 37 53125 34,000 04 Non-owner 20 0 100,000 7 Owner 35 46875 130,000 1 Owner 50 9375 80,000 5 ? Now an 1-NN algorithm with a Euclidean metric could easily be used to find out if the last person is more than likely to own a home. Without the rescaling, the algorithm would have yielded different results. Keeping it short today, but hopefully it was a helpful tip!", 
            "tags": "DataScience", 
            "loc": "https://clamytoe.github.io/rescaling-values.html"
        },
        {
            "title": "About", 
            "text":"Hi, I&#39;m Martin, a.k.a clamytoe, and I am the author of these &#34;ramblings&#34;. Will flesh this out later!", 
            "tags": "pages", 
            "loc": "https://clamytoe.github.io/pages/about.html"
        }        
    ]
}